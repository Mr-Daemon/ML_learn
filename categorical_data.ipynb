{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('data\\melb_data.csv')\n",
    "missing_cols = [col for col in data.columns if data[col].isnull().any()]\n",
    "X = data.drop(['Price'], axis=1)\n",
    "X = X.drop(missing_cols, axis=1)\n",
    "y = data.Price\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.8,test_size=0.2)\n",
    "\n",
    "def score_dataset(train_X, test_X, train_y, test_y):\n",
    "    model = RandomForestRegressor(random_state=0)\n",
    "    model.fit(train_X,train_y)\n",
    "    p_val = model.predict(test_X)\n",
    "    mae = mean_absolute_error(test_y,p_val)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "A categorical variable takes only a limited number of values. Think about enum type in c/Java/python.  \n",
    "You will get an error if you try to plug these variables into most machine learning models in Python without preprocessing them first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Suburb', 'Address', 'Type', 'Method', 'SellerG', 'Date', 'Regionname']\n              Suburb           Address Type Method   SellerG        Date  \\\n0         Abbotsford      85 Turner St    h      S    Biggin   3/12/2016   \n1         Abbotsford   25 Bloomburg St    h      S    Biggin   4/02/2016   \n2         Abbotsford      5 Charles St    h     SP    Biggin   4/03/2017   \n3         Abbotsford  40 Federation La    h     PI    Biggin   4/03/2017   \n4         Abbotsford       55a Park St    h     VB    Nelson   4/06/2016   \n...              ...               ...  ...    ...       ...         ...   \n13575  Wheelers Hill      12 Strada Cr    h      S     Barry  26/08/2017   \n13576   Williamstown     77 Merrett Dr    h     SP  Williams  26/08/2017   \n13577   Williamstown       83 Power St    h      S     Raine  26/08/2017   \n13578   Williamstown      96 Verdon St    h     PI   Sweeney  26/08/2017   \n13579     Yarraville        6 Agnes St    h     SP   Village  26/08/2017   \n\n                       Regionname  \n0           Northern Metropolitan  \n1           Northern Metropolitan  \n2           Northern Metropolitan  \n3           Northern Metropolitan  \n4           Northern Metropolitan  \n...                           ...  \n13575  South-Eastern Metropolitan  \n13576        Western Metropolitan  \n13577        Western Metropolitan  \n13578        Western Metropolitan  \n13579        Western Metropolitan  \n\n[13580 rows x 7 columns]\n"
    }
   ],
   "source": [
    "# find the non-numerical columns\n",
    "\n",
    "index_series = (X.dtypes == 'object')\n",
    "object_cols = list(index_series[index_series].index)\n",
    "print(object_cols)\n",
    "print(X[object_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Label encoding\n",
    "As implmentation in c, we can label these categorical variables by numerical type like integer.\n",
    "\n",
    "<img src=\"static/label_img.png\" style=\"zoom:40%;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "176957.01884388807"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_train_X = train_X.copy()\n",
    "label_test_X = test_X.copy()\n",
    "label_encoder = LabelEncoder()\n",
    "# to prevent data in one column be treated as various type, use \"astype\"\n",
    "for col in object_cols:\n",
    "    label_train_X[col] = label_encoder.fit_transform(train_X[col].astype(str))\n",
    "    label_test_X[col] = label_encoder.fit_transform(test_X[col].astype(str))\n",
    "score_dataset(label_train_X, label_test_X, train_y, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: One-Hot encoding\n",
    "One-hot encoding creates new columns indicating the presence (or absence) of each possible value in the original data.\n",
    "\n",
    "<img src=\"static/one_hot_img.png\" style=\"zoom:40%;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 11370 and input n_features is 3225 ",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-fb2f73bef57f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mOH_test_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_test_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOH_cols_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mscore_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOH_train_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mOH_test_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-42-93a2d1e994b5>\u001b[0m in \u001b[0;36mscore_dataset\u001b[1;34m(train_X, test_X, train_y, test_y)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mmae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmae\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m             raise ValueError(\"Number of features of the model must \"\n\u001b[0m\u001b[0;32m    397\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 11370 and input n_features is 3225 "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "'''\n",
    "avoid errors when the validation data contains classes that aren't represented in the training data and ensures that the encoded columns are returned as a numpy array (instead of a sparse matrix\n",
    "'''\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[object_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.fit_transform(test_X[object_cols]))\n",
    "OH_cols_train.index = train_X[object_cols].index\n",
    "OH_cols_test.index = test_X[object_cols].index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_train_X = train_X.drop(object_cols, axis=1)\n",
    "num_test_X = test_X.drop(object_cols, axis=1)\n",
    "\n",
    "OH_train_X = pd.concat([num_train_X, OH_cols_train], axis=1)\n",
    "OH_test_X = pd.concat([num_test_X, OH_cols_test], axis=1)\n",
    "\n",
    "score_dataset(OH_train_X,OH_test_X,train_y,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the difference?\n",
    "One big and important difference between label encoding and one-hot encoding is when you use label encoding, you assume the variable order -- in some cases that may lead to error; in the contrast, one-hot encoding does not assume an ordering of the categories. But you may not use one-hot encoding if the categorical variable takes on a large number of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bit1249129cc83e44109488de87e2c7875b",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}